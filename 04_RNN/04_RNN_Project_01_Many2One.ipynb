{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dea9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tokenization_kobert import KoBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94425469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc18276",
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder_Path = 'D:/Code/01_Project/02_Study/2022_스터디/04_RNN/00_Data/'\n",
    "Train_Data_Path = os.path.join(Folder_Path, \"nsmc_ratings_train.txt\")\n",
    "Test_Data_Path = os.path.join(Folder_Path, \"nsmc_ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5bbac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = pd.read_csv(Train_Data_Path, sep = \"\\t\", encoding = \"utf-8\").dropna().reset_index(drop = True)\n",
    "Test_Data = pd.read_csv(Test_Data_Path, sep = \"\\t\", encoding = \"utf-8\").dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b7d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Text = list(Train_Data.document)\n",
    "Train_Label = list(Train_Data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2b35a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75170</td>\n",
       "      <td>75170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74825</td>\n",
       "      <td>74825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  document\n",
       "label                 \n",
       "0      75170     75170\n",
       "1      74825     74825"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f78677f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size +1\n",
    "hidden_size = 64\n",
    "batch_size = 512\n",
    "max_length = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29587d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 149995/149995 [00:12<00:00, 11933.75it/s]\n"
     ]
    }
   ],
   "source": [
    "Train_Sequence = []\n",
    "for i in tqdm(range(len(Train_Text))):\n",
    "    sentence = tokenizer.tokenize('[CLS] ' + Train_Text[i] + '[SEP]')\n",
    "    Train_Sequence.append(tokenizer.convert_tokens_to_ids(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ca9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequence = tf.keras.preprocessing.sequence.pad_sequences(Train_Sequence, padding='post', maxlen = max_length)\n",
    "Label = np.expand_dims(np.array(Train_Label), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea5137f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149995, 128), (149995, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sequence.shape, Label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "370f4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inputs = tf.keras.Input(shape = (max_length))\n",
    "Embedding_Layers = tf.keras.layers.Embedding(vocab_size, hidden_size)(Inputs)\n",
    "Layer01_RNN_Forward = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=False, go_backwards=False)(Embedding_Layers)\n",
    "Classifier = tf.keras.layers.Dense(1, activation = 'sigmoid')(Layer01_RNN_Forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4de41216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 128, 64)           512192    \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520,513\n",
      "Trainable params: 520,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.Model(Inputs, Classifier)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68e9b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 2)\n",
    "model1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03cef103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 55s 231ms/step - loss: 0.6536 - accuracy: 0.6090 - val_loss: 0.6139 - val_accuracy: 0.6763\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 55s 232ms/step - loss: 0.5953 - accuracy: 0.6945 - val_loss: 0.5996 - val_accuracy: 0.6880\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 55s 235ms/step - loss: 0.5716 - accuracy: 0.7138 - val_loss: 0.5913 - val_accuracy: 0.7011\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 54s 231ms/step - loss: 0.5522 - accuracy: 0.7293 - val_loss: 0.5964 - val_accuracy: 0.6876\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 55s 233ms/step - loss: 0.5743 - accuracy: 0.7096 - val_loss: 0.5950 - val_accuracy: 0.6912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a5a20bee0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(Sequence, Label, epochs=20, batch_size= batch_size, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed5621c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 49997/49997 [00:04<00:00, 11964.28it/s]\n"
     ]
    }
   ],
   "source": [
    "Test_Text = list(Test_Data.document)\n",
    "Test_Label = list(Test_Data.label)\n",
    "\n",
    "Test_Sequence = []\n",
    "for i in tqdm(range(len(Test_Text))):\n",
    "    sentence = tokenizer.tokenize('[CLS] ' + Test_Text[i] + '[SEP]')\n",
    "    Test_Sequence.append(tokenizer.convert_tokens_to_ids(sentence))\n",
    "    \n",
    "test_text = tf.keras.preprocessing.sequence.pad_sequences(Test_Sequence, padding='post', maxlen = max_length)\n",
    "test_label = np.expand_dims(np.array(Test_Label), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d52b1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 35s 22ms/step - loss: 0.5962 - accuracy: 0.6896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5962127447128296, 0.6896213889122009]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_text, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b84e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size +1\n",
    "hidden_size = 32\n",
    "batch_size = 512\n",
    "max_length = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5bceaf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "Inputs = tf.keras.Input(shape = (max_length))\n",
    "Embedding_Layers = tf.keras.layers.Embedding(vocab_size, hidden_size)(Inputs)\n",
    "Layer01_GRU_Forward = tf.keras.layers.GRU(hidden_size, activation='relu', return_sequences=True, go_backwards=False, dropout = 0.1)(Embedding_Layers)\n",
    "\n",
    "Layer02_GRU_Backward = tf.keras.layers.GRU(hidden_size, activation='relu', return_sequences=True, go_backwards=True, dropout = 0.1)(Embedding_Layers)\n",
    "\n",
    "Layer_Concatenate = tf.keras.layers.Concatenate()([Layer01_GRU_Forward, Layer02_GRU_Backward])\n",
    "\n",
    "Flatten = tf.keras.layers.Flatten()(Layer_Concatenate)\n",
    "\n",
    "Classifier = tf.keras.layers.Dense(1, activation = 'sigmoid')(Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6febf85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_18 (Embedding)       (None, 128, 32)      256096      ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " gru_14 (GRU)                   (None, 128, 32)      6336        ['embedding_18[0][0]']           \n",
      "                                                                                                  \n",
      " gru_15 (GRU)                   (None, 128, 32)      6336        ['embedding_18[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 64)      0           ['gru_14[0][0]',                 \n",
      "                                                                  'gru_15[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 8192)         0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            8193        ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 276,961\n",
      "Trainable params: 276,961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Model(Inputs, Classifier)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "642a4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "491701d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 278s 1s/step - loss: 0.4822 - accuracy: 0.7591 - val_loss: 0.3950 - val_accuracy: 0.8235\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 290s 1s/step - loss: 0.3710 - accuracy: 0.8368 - val_loss: 0.3774 - val_accuracy: 0.8312\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 298s 1s/step - loss: 0.3492 - accuracy: 0.8463 - val_loss: 0.3636 - val_accuracy: 0.8386\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 292s 1s/step - loss: 0.3295 - accuracy: 0.8559 - val_loss: 0.3592 - val_accuracy: 0.8405\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 287s 1s/step - loss: 0.3139 - accuracy: 0.8637 - val_loss: 0.3619 - val_accuracy: 0.8425\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.3003 - accuracy: 0.8710 - val_loss: 0.3594 - val_accuracy: 0.8433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a61018e20>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(Sequence, Label, epochs=20, batch_size= batch_size, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "56afa6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 210s 134ms/step - loss: 0.3663 - accuracy: 0.8388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3662944436073303, 0.8387903571128845]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c669d2",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d4be741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 149995/149995 [00:00<00:00, 2584332.06it/s]\n"
     ]
    }
   ],
   "source": [
    "Num_Sequence = []\n",
    "for i in tqdm(range(len(Train_Sequence))):\n",
    "    Num_Sequence.append(len(Train_Sequence[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9df29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_num_len = np.array(Num_Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d577a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12.,  19.,  29.,  66.,  88., 143.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(temp_num_len, [25, 50, 75, 95, 99, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
